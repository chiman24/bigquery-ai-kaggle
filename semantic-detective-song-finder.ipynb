{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0e687f",
   "metadata": {},
   "source": [
    "# From Theme to Setlist \n",
    "## Line-level Semantic Lyric Finder (BigQuery AI)\n",
    "\n",
    "**Approach 2 – The Semantic Detective**: Given a short, textual theme, find songs whose **lyric lines** best match in meaning (not just keywords). \n",
    "\n",
    "We create tables, load song data from text files in GCS into the tables, create vector embeddings with **BigQuery ML**, perform **vector search**, then roll up to the **best matching line** per song for explainability.\n",
    "\n",
    "**Notebook Guide**\n",
    "1. Setup (config, auth check)  \n",
    "2. Initialize GCP clients - bigquery, storage  \n",
    "3. Create/Verify Dataset \n",
    "4. Create Remote Model  \n",
    "5. Create _songs_ table \n",
    "6. Create _song_lines_ table  \n",
    "7. Define functions for ETL Pipeline\n",
    "8. Prepare data for loading\n",
    "9. Load data into _songs_ and _song_lines_ tables\n",
    "10. Generate Lyric Embeddings\n",
    "11. Search by Theme (Vector Search)\n",
    "12. Evaluate Results\n",
    "\n",
    "> Run top to bottom. If you don’t have GCP auth on Kaggle, skim the SQL and metrics sections to follow the logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb66ac",
   "metadata": {},
   "source": [
    "![\"Architectural Diagram\"](images/architectural-diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50434e83-c96e-4671-9bc0-5ffef310ca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BigQuery Storage client so to_dataframe can use the fast path (no warning)\n",
    "!pip install -q \"google-cloud-bigquery[bqstorage,pandas]\" google-cloud-bigquery-storage pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f867f63-b1ed-41e5-b63f-33c383ede911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= USER CONFIG (EDIT THESE) =======\n",
    "PROJECT_ID   = \"bq-vector-demo\"     # Replace with your own GCP Project Id\n",
    "LOCATION     = \"us\"                 # BigQuery dataset location / region\n",
    "DATASET      = \"my_dataset\"         # e.g., 'choir_ai'\n",
    "BQ_CONN      = \"DEFAULT\"            # Or fully-qualified, e.g. 'your-project.us.vertex_conn'\n",
    "EMBED_MODEL  = \"text-embedding-005\" # or 'text-multilingual-embedding-002'\n",
    "THEME_TEXT   = \"Uncommon Favor\"     # try different monthly themes\n",
    "TOP_K        = 10\n",
    "GCS_BUCKET   = \"bht-song-lyrics\"\n",
    "\n",
    "# Optional: index tuning\n",
    "# INDEX_NAME   = \"songs_lyric_idx\"\n",
    "DISTANCE     = \"COSINE\"             # COSINE | DOT_PRODUCT | EUCLIDEAN\n",
    "# IVF_NUM_LISTS = 100                 # Try 100–200 for small demos\n",
    "\n",
    "# ======= DO NOT EDIT BELOW (unless you know why) =======\n",
    "TABLE_SONGS          = f\"`{PROJECT_ID}.{DATASET}.songs`\"\n",
    "TABLE_SONG_LINES     = f\"`{PROJECT_ID}.{DATASET}.song_lines`\"\n",
    "TABLE_SONG_EMB       = f\"`{PROJECT_ID}.{DATASET}.song_embeddings`\"\n",
    "TABLE_SONG_LINE_EMB  = f\"`{PROJECT_ID}.{DATASET}.song_line_embeddings`\"\n",
    "MODEL_REMOTE         = f\"`{PROJECT_ID}.{DATASET}.embed_text`\"\n",
    "# VECTOR_INDEX         = f\"{PROJECT_ID}.{DATASET}.{INDEX_NAME}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6a501-269a-4f00-a18f-4080fb89b030",
   "metadata": {},
   "source": [
    "# 1) Initialize GCP clients - bigquery, storage\n",
    "We'll use **bigquery** to run our queries and **storage** to interact with our GCS bucket which contains our song files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e6a31-1a0e-4492-8c33-2f32e4a4c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "bucket = storage_client.bucket(GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c3def-37f6-47d8-99f7-0c093670ef0c",
   "metadata": {},
   "source": [
    "# 2) Create/Verify Dataset\n",
    "This creates the dataset if it does not exist.  (On GCP, a **_dataset_** is like a folder within which you create your tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c772148-22d1-44f3-b365-96d153158b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import Conflict\n",
    "\n",
    "def ensure_dataset(dataset_id: str, location: str):\n",
    "    ds_ref = bigquery.Dataset(dataset_id)\n",
    "    ds_ref.location = location\n",
    "    try:\n",
    "        bq_client.create_dataset(ds_ref)\n",
    "        print(\"Created dataset:\", dataset_id)\n",
    "    except Conflict:\n",
    "        print(\"Dataset exists:\", dataset_id)\n",
    "\n",
    "ensure_dataset(f\"{PROJECT_ID}.{DATASET}\", LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442ba838-45e7-43aa-8eb9-de9668dd2f5c",
   "metadata": {},
   "source": [
    "# 3) Create Remote Model\n",
    "\n",
    "We reference a Vertex AI text-embedding endpoint via a **remote model**.\n",
    "\n",
    "- Use `BQ_CONN = \"DEFAULT\"` if you have a default connection set.\n",
    "- Otherwise set it to your explicit connection name, e.g., `your-project.us.vertex_conn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcfc45-6b6a-43f4-b94b-bd8786bd8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_sql=f\"\"\"\n",
    "CREATE OR REPLACE MODEL {MODEL_REMOTE}\n",
    "REMOTE WITH CONNECTION {BQ_CONN}\n",
    "OPTIONS (\n",
    "  -- pick one of the supported text embedding endpoints\n",
    "  -- examples: 'text-embedding-005'  or  'text-multilingual-embedding-002'\n",
    "  ENDPOINT = 'text-multilingual-embedding-002'\n",
    ");\n",
    "\"\"\"\n",
    "bq_client.query(create_model_sql).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a96bec-5655-4bdb-aa98-a2dc54dcea65",
   "metadata": {},
   "source": [
    "# 4) Create our _songs_ table\n",
    "### Schema:  (song_id, song_title, lyrics, artist, created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51557ba5-7499-41dc-90bd-8dcb76e33bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_songs_table_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {TABLE_SONGS}\n",
    "(\n",
    "  song_id     STRING NOT NULL,            -- we’ll set this with GENERATE_UUID() on insert\n",
    "  song_title  STRING,\n",
    "  lyrics      STRING,\n",
    "  artist      STRING,\n",
    "  created_at  TIMESTAMP NOT NULL          -- we’ll set this with CURRENT_TIMESTAMP() on insert\n",
    ")\n",
    "PARTITION BY DATE(created_at)             -- optional but recommended for time-based queries\n",
    "CLUSTER BY artist, song_title;            -- optional: helps some query patterns\n",
    "\"\"\"\n",
    "result = bq_client.query(create_songs_table_sql).result()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b243b-2ebf-4580-a38c-72b78d162da5",
   "metadata": {},
   "source": [
    "# 5) Create our _song_lines_ table\n",
    "### Schema: (song_id, son_title, artist, line_id, line_text, section, created_at)\n",
    "This will give us more detailed information about which actual lines in a song match the given theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e4a1b-c36f-4186-851d-1a2f9a401976",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_song_lines_table_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE {TABLE_SONG_LINES}\n",
    "(\n",
    "  song_id     STRING NOT NULL,            \n",
    "  song_title  STRING,\n",
    "  artist      STRING,\n",
    "  line_id     INT64,\n",
    "  line_text   STRING,\n",
    "  section     STRING,\n",
    "  created_at  TIMESTAMP NOT NULL        \n",
    ")\n",
    "PARTITION BY DATE(created_at)             \n",
    "CLUSTER BY artist, song_title;            \n",
    "\"\"\"\n",
    "bq_client.query(create_song_lines_table_sql).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bae6a9-525e-4e2d-a6d5-de34747fa1ff",
   "metadata": {},
   "source": [
    "# 6) Define functions for our ETL Pipeline\n",
    "The functions below help us load song data from the files in our GCS bucket into our BigQuery tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca92b24-7191-46f9-a0d3-a579b86d076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, uuid\n",
    "import pandas as pd\n",
    "\n",
    "# File names are expected to be in the format \"Song Title - Artist.txt\"\n",
    "def parse_filename(blob_name):\n",
    "    # Use non-greedy title, then artist, and ensure it ends with .txt\n",
    "    m = re.match(r'(?P<song_title>.+?)\\s-\\s(?P<artist>.+)\\.txt$', blob_name, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m['song_title'], m['artist']\n",
    "    return None, None\n",
    "\n",
    "# Get the contents of the file.\n",
    "def retrieve_lyrics(blob):\n",
    "    content = blob.download_as_text()\n",
    "    return content.strip()\n",
    "\n",
    "# Loop through blobs in the bucket and prepare data for BigQuery\n",
    "def prepare_data_for_loading():\n",
    "    rows = []\n",
    "    for blob in bucket.list_blobs():\n",
    "        title, artist = parse_filename(blob.name)\n",
    "        if title and artist:\n",
    "            song_id = str(uuid.uuid4())\n",
    "            lyrics = retrieve_lyrics(blob)\n",
    "            rows.append({\"song_id\": song_id, \"song_title\": title, \"artist\": artist, \"lyrics\": lyrics})\n",
    "    return rows\n",
    "\n",
    "# Load songs into staging table first\n",
    "def populate_songs_staging(rows):\n",
    "\n",
    "    print(f\"Inserting {len(rows)} songs into 'songs_staging' table...\")\n",
    "\n",
    "    songs_df = pd.DataFrame(rows)\n",
    "    bq_client.load_table_from_dataframe(songs_df, f\"{PROJECT_ID}.{DATASET}.songs_staging\").result()\n",
    "\n",
    "    \n",
    "# Merge from staging to main songs table\n",
    "def populate_songs(rows):\n",
    "    populate_songs_staging(rows)\n",
    "    sql = f\"\"\"\n",
    "    MERGE `{PROJECT_ID}.{DATASET}.songs` T\n",
    "    USING `{PROJECT_ID}.{DATASET}.songs_staging` S\n",
    "    ON T.song_id = S.song_id\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        song_title = S.song_title,\n",
    "        lyrics     = S.lyrics,\n",
    "        artist     = S.artist\n",
    "    WHEN NOT MATCHED THEN\n",
    "    INSERT (song_id, song_title, lyrics, artist, created_at)\n",
    "    VALUES (S.song_id, S.song_title, S.lyrics, S.artist, CURRENT_TIMESTAMP());\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client.query(sql).result()\n",
    "    print(f\"Upserted {len(rows)} songs into 'songs' table.\")\n",
    "    # Clear staging table after merge\n",
    "    bq_client.query(f\"DELETE FROM `{PROJECT_ID}.{DATASET}.songs_staging` WHERE TRUE\").result()\n",
    "    print(\"Cleared 'songs_staging' table.\")\n",
    "\n",
    "# Load songs lines from lyrics into staging table first\n",
    "def populate_song_lines_staging(rows):\n",
    "    all_lines = []\n",
    "    for row in rows:\n",
    "        song_id = row[\"song_id\"]\n",
    "        song_title = row[\"song_title\"]\n",
    "        artist = row[\"artist\"]\n",
    "        lyrics = row[\"lyrics\"]\n",
    "\n",
    "        section_regex = re.compile(r'^\\s*(?:verse|bridge|intro|vamp|tag|ending|outro|chorus)\\s*(\\d+)?\\s*:?\\s*$',\n",
    "                        re.IGNORECASE)\n",
    "        \n",
    "        lyrics = normalize_newlines(lyrics)\n",
    "        lines = [line.strip() for line in lyrics.split('\\n') if line.strip()]\n",
    "\n",
    "        section = \"Unknown\" # Default section if none found\n",
    "        for i, line in enumerate(lines):\n",
    "            if section_regex.match(line):\n",
    "                section = section_regex.match(line).group(0)\n",
    "                continue\n",
    "            line_id = i + 1\n",
    "            # strip trailing colon (if present) from section headers\n",
    "            section = section.rstrip(':')\n",
    "            all_lines.append({\n",
    "                \"song_id\": song_id,\n",
    "                \"song_title\": song_title,\n",
    "                \"artist\": artist,\n",
    "                \"line_id\": line_id,\n",
    "                \"line_text\": line,\n",
    "                \"section\": section\n",
    "            })\n",
    "    \n",
    "    print(f\"Inserting {len(all_lines)} song lines into 'song_lines_staging' table...\")\n",
    "\n",
    "    lines_df = pd.DataFrame(all_lines)\n",
    "    bq_client.load_table_from_dataframe(lines_df, f\"{PROJECT_ID}.{DATASET}.song_lines_staging\").result()\n",
    "\n",
    "    print(f\"Inserted {len(all_lines)} song lines into 'song_lines_staging' table.\")\n",
    "\n",
    "# Load data from the rows dataframe into the song_lines table\n",
    "def populate_song_lines(rows):\n",
    "    populate_song_lines_staging(rows)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    MERGE `{PROJECT_ID}.{DATASET}.song_lines` T\n",
    "    USING `{PROJECT_ID}.{DATASET}.song_lines_staging` S\n",
    "    ON T.song_id = S.song_id AND T.line_id = S.line_id\n",
    "    WHEN MATCHED THEN UPDATE SET\n",
    "        line_text = S.line_text,\n",
    "        section   = S.section,\n",
    "        song_title = S.song_title,\n",
    "        artist     = S.artist\n",
    "    WHEN NOT MATCHED THEN\n",
    "    INSERT (song_id, song_title, artist, line_id, line_text, section, created_at)\n",
    "    VALUES (S.song_id, S.song_title, S.artist, S.line_id, S.line_text, S.section, CURRENT_TIMESTAMP());\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client.query(sql).result()\n",
    "    print(f\"Upserted song lines into 'song_lines' table.\")\n",
    "    # Clear staging table after merge\n",
    "    bq_client.query(f\"DELETE FROM `{PROJECT_ID}.{DATASET}.song_lines_staging` WHERE TRUE\").result()\n",
    "    print(\"Cleared 'song_lines_staging' table.\")\n",
    "\n",
    "\n",
    "# Replace various newline representations with standard \\n\n",
    "def normalize_newlines(text):\n",
    "    return re.sub(r'\\r\\n|\\r|\\n', '\\n', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5277a-326b-4bbe-addc-a87e01890b07",
   "metadata": {},
   "source": [
    "# 7) Prepare our data for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b514f82-7d7d-4bd3-a3cf-7b72cad0fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read content from text files in GCS bucket\n",
    "# Return a list of dictionary objects ready to load into BigQuery.\n",
    "\n",
    "rows = prepare_data_for_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b38e1-fa07-4979-8489-c77786f776a8",
   "metadata": {},
   "source": [
    "# 8) Load data into our _songs_ and _song_lines_ tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff38795-7e79-47c0-9ac6-88381ee2e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (rows) into our \"songs\" and \"song_lines\" tables\n",
    "\n",
    "populate_songs(rows)\n",
    "populate_song_lines(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931c4d52-dbe4-4388-b275-4f620b6a0222",
   "metadata": {},
   "source": [
    "# 9) Generate Lyric Embeddings \n",
    "\n",
    "We call `ML.GENERATE_EMBEDDING` with `task_type='RETRIEVAL_DOCUMENT'` for song items.\n",
    "The function returns the original columns plus a vector column. We write the result into a new table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dedbc9-e4f3-4adc-8dd5-0ad1fbbedd7e",
   "metadata": {},
   "source": [
    "### Create table with embeddings for _songs_ table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9f3d2-786b-4d67-b2f6-1846c9d4ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_song_embeddings_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.song_embeddings` AS\n",
    "SELECT\n",
    "  s.song_id,\n",
    "  s.song_title,\n",
    "  s.lyrics,\n",
    "  -- This returns an ARRAY<FLOAT64> when flatten_json_output=TRUE\n",
    "  emb.ml_generate_embedding_result AS lyric_vec\n",
    "FROM ML.GENERATE_EMBEDDING(\n",
    "  MODEL `{DATASET}.embed_text`,\n",
    "  (\n",
    "    SELECT\n",
    "      lyrics AS content,  -- alias to 'content' as required\n",
    "      song_id, song_title\n",
    "    FROM `{DATASET}.songs`\n",
    "  ),\n",
    "  -- task_type helps embedding quality; RETRIEVAL_DOCUMENT is a good fit for corpus items\n",
    "  STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_DOCUMENT' AS task_type)\n",
    ") AS emb\n",
    "JOIN `{DATASET}.songs` AS s\n",
    "USING (song_id);\n",
    "\"\"\"\n",
    "bq_client.query(generate_song_embeddings_sql).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4226c-494f-427a-a417-7c67c7442bd7",
   "metadata": {},
   "source": [
    "### Create table with embeddings for _song_lines_ table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfa2ef-69d7-4128-ba42-d1bb41286cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_song_line_embeddings_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.song_line_embeddings` AS\n",
    "SELECT\n",
    "  s.song_id,\n",
    "  s.line_id,\n",
    "  s.song_title,\n",
    "  s.artist,\n",
    "  s.line_text,\n",
    "  s.section,\n",
    "  emb.ml_generate_embedding_result AS line_vec     -- ARRAY<FLOAT64>\n",
    "FROM ML.GENERATE_EMBEDDING(\n",
    "  MODEL `{PROJECT_ID}.{DATASET}.embed_text`,\n",
    "  (\n",
    "    SELECT\n",
    "      line_text AS content,    -- required alias\n",
    "      song_id, line_id, song_title, artist\n",
    "    FROM `{PROJECT_ID}.{DATASET}.song_lines`\n",
    "  ),\n",
    "  STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_DOCUMENT' AS task_type)\n",
    ") AS emb\n",
    "JOIN `{PROJECT_ID}.{DATASET}.song_lines` AS s\n",
    "USING (song_id, line_id);\n",
    "\"\"\"\n",
    "bq_client.query(generate_song_line_embeddings_sql).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a7e1c-bb22-43c5-8f25-3b6ac10cacdc",
   "metadata": {},
   "source": [
    "# 10) Search by Theme\n",
    "\n",
    "### Now, we're ready to run a search of a given theme against our data.  There are 2 main steps involved: \n",
    "1. Generate an embedding of the theme (again using ML.GENERATE_EMBEDDING)\n",
    "2. Use the theme embedding to search against our embeddings table (using VECTOR_SEARCH)\n",
    "\n",
    "We embed the **theme** with `task_type='RETRIEVAL_QUERY'` and then call `VECTOR_SEARCH`.\n",
    "Adjust `TOP_K` as desired.\n",
    "\n",
    "_**Note:  For the purposes of this demonstration, we're only searching the song_line_embeddings.  The song_embeddings aren't being used currently**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b6a9a-d025-4fb5-9576-4366c44489e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(theme: str, limit):\n",
    "    theme = theme.strip()\n",
    "    if not theme or not isinstance(theme, str):\n",
    "        print(\"Invalid theme provided for search.  Please provide a non-empty string.\")\n",
    "        return\n",
    "    vector_search_sql = f\"\"\"\n",
    "    WITH theme AS (\n",
    "      SELECT ml_generate_embedding_result AS theme_vec\n",
    "      FROM ML.GENERATE_EMBEDDING(\n",
    "        MODEL `{PROJECT_ID}.{DATASET}.embed_text`,\n",
    "        (SELECT @theme AS content),\n",
    "        STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_QUERY' AS task_type)\n",
    "      )\n",
    "    ),\n",
    "    top_lines AS (\n",
    "      SELECT\n",
    "        base.song_id, base.song_title, base.artist, base.line_text, base.section, distance\n",
    "      FROM VECTOR_SEARCH(\n",
    "        TABLE `{PROJECT_ID}.{DATASET}.song_line_embeddings`,\n",
    "        'line_vec',\n",
    "        (SELECT theme_vec FROM theme),\n",
    "        top_k => 400,\n",
    "        distance_type => 'COSINE'\n",
    "      )\n",
    "    )\n",
    "    SELECT song_id, song_title, artist, section, best_line_text\n",
    "    FROM (\n",
    "      SELECT\n",
    "        song_id,\n",
    "        song_title,\n",
    "        artist,\n",
    "        line_text AS best_line_text,\n",
    "        section,\n",
    "        distance AS best_distance,\n",
    "        ROW_NUMBER() OVER (PARTITION BY song_id ORDER BY distance) AS rn\n",
    "      FROM top_lines\n",
    "    )\n",
    "    WHERE rn = 1\n",
    "    ORDER BY best_distance\n",
    "    LIMIT {limit};    -- top n songs with their best line\n",
    "    \"\"\"\n",
    "\n",
    "    job_config=bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\"theme\",\"STRING\",theme)\n",
    "    ])\n",
    "    vs_df = bq_client.query(vector_search_sql, job_config=job_config).result().to_dataframe()\n",
    "    return vs_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "172b9976-ce66-4fe5-b77c-2e6dd543ec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>section</th>\n",
       "      <th>best_line_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c628444c-dee3-44f2-83f3-91aa1e15c5fb</td>\n",
       "      <td>Goodness Of God</td>\n",
       "      <td>Jenn Johnson</td>\n",
       "      <td>Verse 2</td>\n",
       "      <td>And I have lived in the goodness of God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cf016486-bc27-4ad3-8d25-d2f81b2262cc</td>\n",
       "      <td>Your Grace Is Enough</td>\n",
       "      <td>Planetshakers</td>\n",
       "      <td>Verse 2</td>\n",
       "      <td>Great is Your love and justice, God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d36d556b-946c-4979-80b9-f42a62867c29</td>\n",
       "      <td>My God Is Awesome</td>\n",
       "      <td>Charles Jenkins</td>\n",
       "      <td>Verse 2</td>\n",
       "      <td>My God is awesome \n",
       "Today i am forgiven \n",
       "His grac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eebcf980-5a82-4618-8bd5-bb1a3e4d3cdd</td>\n",
       "      <td>Righteousness</td>\n",
       "      <td>Godwin Smart</td>\n",
       "      <td>Verse 1</td>\n",
       "      <td>It's just what His grace did for us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4fa12c17-7294-430f-9102-7ec8deb20b13</td>\n",
       "      <td>My Everything</td>\n",
       "      <td>Joe Mettle</td>\n",
       "      <td>Verse</td>\n",
       "      <td>Words are not enough to say thank you Lord,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4e3011e9-d68d-40e8-b1dd-4fd51908c895</td>\n",
       "      <td>Made Me Glad</td>\n",
       "      <td>Hillsong</td>\n",
       "      <td>Verse 2</td>\n",
       "      <td>For You have made me glad, and I'll say of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>05cb17f3-7438-4c1e-8873-64a2bf8088d2</td>\n",
       "      <td>Every Praise</td>\n",
       "      <td>Hezekiah Walker</td>\n",
       "      <td>Chorus</td>\n",
       "      <td>Every praise every praise is to our God.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7e6902d4-341e-4ff5-a3ad-394e871f4544</td>\n",
       "      <td>Your Goodness</td>\n",
       "      <td>Dunsin Oyekan</td>\n",
       "      <td>Chorus</td>\n",
       "      <td>Your goodness looks good on us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9353c4ff-ad9f-4295-872a-4bc69de4a101</td>\n",
       "      <td>Shout It Loud</td>\n",
       "      <td>Sinach</td>\n",
       "      <td>Verse</td>\n",
       "      <td>Of your goodness and your grace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5ea735cd-c078-4a8b-a810-17a25eb12361</td>\n",
       "      <td>Praise Him</td>\n",
       "      <td>Mofetolu</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Give Him your praise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                song_id            song_title  \\\n",
       "0  c628444c-dee3-44f2-83f3-91aa1e15c5fb       Goodness Of God   \n",
       "1  cf016486-bc27-4ad3-8d25-d2f81b2262cc  Your Grace Is Enough   \n",
       "2  d36d556b-946c-4979-80b9-f42a62867c29     My God Is Awesome   \n",
       "3  eebcf980-5a82-4618-8bd5-bb1a3e4d3cdd         Righteousness   \n",
       "4  4fa12c17-7294-430f-9102-7ec8deb20b13         My Everything   \n",
       "5  4e3011e9-d68d-40e8-b1dd-4fd51908c895          Made Me Glad   \n",
       "6  05cb17f3-7438-4c1e-8873-64a2bf8088d2          Every Praise   \n",
       "7  7e6902d4-341e-4ff5-a3ad-394e871f4544         Your Goodness   \n",
       "8  9353c4ff-ad9f-4295-872a-4bc69de4a101         Shout It Loud   \n",
       "9  5ea735cd-c078-4a8b-a810-17a25eb12361            Praise Him   \n",
       "\n",
       "            artist  section                                     best_line_text  \n",
       "0     Jenn Johnson  Verse 2            And I have lived in the goodness of God  \n",
       "1    Planetshakers  Verse 2                Great is Your love and justice, God  \n",
       "2  Charles Jenkins  Verse 2  My God is awesome\n",
       "Today i am forgiven\n",
       "His grac...  \n",
       "3     Godwin Smart  Verse 1                It's just what His grace did for us  \n",
       "4       Joe Mettle    Verse        Words are not enough to say thank you Lord,  \n",
       "5         Hillsong  Verse 2  For You have made me glad, and I'll say of the...  \n",
       "6  Hezekiah Walker   Chorus           Every praise every praise is to our God.  \n",
       "7    Dunsin Oyekan   Chorus                     Your goodness looks good on us  \n",
       "8           Sinach    Verse                    Of your goodness and your grace  \n",
       "9         Mofetolu  Unknown                               Give Him your praise  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for songs that align with a theme (e.g. \"Divine Provision\"):\n",
    "\n",
    "df = search(\"God's goodness\", 10)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31e580-afbe-4967-8084-656fd396c923",
   "metadata": {},
   "source": [
    "# 11) Evaluation of results\n",
    "\n",
    "#### To measure the validity of our results, we'll create a tiny labeled set of (theme, song_title, label) where \"label\" is in {0 - 3} and \"3\" indicates a strong match. We'll then compare this labeled set with our vector search results and use the Normalized Discounted Cumulative Gain (NDCG) and Mean Reciprocal Rank (MRR) metrics to validate our results.\n",
    "\n",
    "1. **Normalized Discounted Cumulative Gain (NDCG)** - A standard metric for graded relevance\n",
    "2. **Mean Reciprocal Rank (MMR)** - A metric that measures the first relevant hit/result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3bb57310-d839-4b03-b442-3d5f7b7c9ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8bc59\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_8bc59_level0_col0\" class=\"col_heading level0 col0\" >theme</th>\n",
       "      <th id=\"T_8bc59_level0_col1\" class=\"col_heading level0 col1\" >song_title</th>\n",
       "      <th id=\"T_8bc59_level0_col2\" class=\"col_heading level0 col2\" >rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row0_col0\" class=\"data row0 col0\" >God's goodness</td>\n",
       "      <td id=\"T_8bc59_row0_col1\" class=\"data row0 col1\" >Goodness Of God</td>\n",
       "      <td id=\"T_8bc59_row0_col2\" class=\"data row0 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row1_col0\" class=\"data row1 col0\" >God's goodness</td>\n",
       "      <td id=\"T_8bc59_row1_col1\" class=\"data row1 col1\" >You are good</td>\n",
       "      <td id=\"T_8bc59_row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row2_col0\" class=\"data row2 col0\" >God's goodness</td>\n",
       "      <td id=\"T_8bc59_row2_col1\" class=\"data row2 col1\" >Your Goodness</td>\n",
       "      <td id=\"T_8bc59_row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row3_col0\" class=\"data row3 col0\" >God's goodness</td>\n",
       "      <td id=\"T_8bc59_row3_col1\" class=\"data row3 col1\" >For your glory</td>\n",
       "      <td id=\"T_8bc59_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row4_col0\" class=\"data row4 col0\" >God's goodness</td>\n",
       "      <td id=\"T_8bc59_row4_col1\" class=\"data row4 col1\" >Beyond me</td>\n",
       "      <td id=\"T_8bc59_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row5_col0\" class=\"data row5 col0\" >Name above all names</td>\n",
       "      <td id=\"T_8bc59_row5_col1\" class=\"data row5 col1\" >The Name of Jesus</td>\n",
       "      <td id=\"T_8bc59_row5_col2\" class=\"data row5 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row6_col0\" class=\"data row6 col0\" >Name above all names</td>\n",
       "      <td id=\"T_8bc59_row6_col1\" class=\"data row6 col1\" >No Other Name</td>\n",
       "      <td id=\"T_8bc59_row6_col2\" class=\"data row6 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row7_col0\" class=\"data row7 col0\" >Name above all names</td>\n",
       "      <td id=\"T_8bc59_row7_col1\" class=\"data row7 col1\" >One Name</td>\n",
       "      <td id=\"T_8bc59_row7_col2\" class=\"data row7 col2\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row8_col0\" class=\"data row8 col0\" >Name above all names</td>\n",
       "      <td id=\"T_8bc59_row8_col1\" class=\"data row8 col1\" >Holy Forever</td>\n",
       "      <td id=\"T_8bc59_row8_col2\" class=\"data row8 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row9_col0\" class=\"data row9 col0\" >Name above all names</td>\n",
       "      <td id=\"T_8bc59_row9_col1\" class=\"data row9 col1\" >Everybody clap your hands</td>\n",
       "      <td id=\"T_8bc59_row9_col2\" class=\"data row9 col2\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row10_col0\" class=\"data row10 col0\" >Love</td>\n",
       "      <td id=\"T_8bc59_row10_col1\" class=\"data row10 col1\" >Reckless Love</td>\n",
       "      <td id=\"T_8bc59_row10_col2\" class=\"data row10 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row11_col0\" class=\"data row11 col0\" >Love</td>\n",
       "      <td id=\"T_8bc59_row11_col1\" class=\"data row11 col1\" >No Greater Love</td>\n",
       "      <td id=\"T_8bc59_row11_col2\" class=\"data row11 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row12_col0\" class=\"data row12 col0\" >Love</td>\n",
       "      <td id=\"T_8bc59_row12_col1\" class=\"data row12 col1\" >More Than Anything</td>\n",
       "      <td id=\"T_8bc59_row12_col2\" class=\"data row12 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row13_col0\" class=\"data row13 col0\" >Love</td>\n",
       "      <td id=\"T_8bc59_row13_col1\" class=\"data row13 col1\" >Dwelling Places</td>\n",
       "      <td id=\"T_8bc59_row13_col2\" class=\"data row13 col2\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_8bc59_row14_col0\" class=\"data row14 col0\" >Love</td>\n",
       "      <td id=\"T_8bc59_row14_col1\" class=\"data row14 col1\" >His Love</td>\n",
       "      <td id=\"T_8bc59_row14_col2\" class=\"data row14 col2\" >2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x139655f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, we'll hand label a small dataframe of themes amd matching songs based on our\n",
    "# human knowledge/domain expertise.\n",
    "\n",
    "labels = pd.DataFrame([\n",
    "    # theme, song_id, label (Scale of 0 - 3, 1 = best)\n",
    "    [\"God's goodness\", \"Goodness Of God\", 3],\n",
    "    [\"God's goodness\", \"You are good\", 2],\n",
    "    [\"God's goodness\", \"Your Goodness\", 3],\n",
    "    [\"God's goodness\", \"For your glory\", 0],\n",
    "    [\"God's goodness\", \"Beyond me\", 1],\n",
    "    [\"Name above all names\", \"The Name of Jesus\", 3],\n",
    "    [\"Name above all names\", \"No Other Name\", 3],\n",
    "    [\"Name above all names\", \"One Name\", 2],\n",
    "    [\"Name above all names\", \"Holy Forever\", 3],\n",
    "    [\"Name above all names\", \"Everybody clap your hands\", 1],\n",
    "    [\"Love\", \"Reckless Love\", 3],\n",
    "    [\"Love\", \"No Greater Love\", 3],\n",
    "    [\"Love\", \"More Than Anything\", 3],\n",
    "    [\"Love\", \"Dwelling Places\", 3],\n",
    "    [\"Love\", \"His Love\", 2]\n",
    "], columns=[\"theme\", \"song_title\", \"rel\"])\n",
    "\n",
    "display(labels.style.hide(axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efc1fd-0255-46dc-bc9a-5e4f113bc287",
   "metadata": {},
   "source": [
    "### Define a \"search_and_rank\" function so we can compare the rankings of our vector search with the rankings of our labeled set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fc2a7b46-aa04-46da-bf8e-bb4e389d1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT=\"bq-vector-demo\"; DATASET=\"my_dataset\"; TOP_K=20\n",
    "client = bigquery.Client(project=PROJECT)\n",
    "\n",
    "def search_and_rank(theme: str, top_k: int=TOP_K) -> pd.DataFrame:\n",
    "    sql = f\"\"\"\n",
    "    WITH theme AS (\n",
    "      SELECT ml_generate_embedding_result AS theme_vec\n",
    "      FROM ML.GENERATE_EMBEDDING(\n",
    "        MODEL `{PROJECT}.{DATASET}.embed_text`,\n",
    "        (SELECT @theme AS content),\n",
    "        STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_QUERY' AS task_type)\n",
    "      )\n",
    "    ),\n",
    "    lines AS (\n",
    "      SELECT base.song_id, base.song_title, base.line_id, base.line_text, distance\n",
    "      FROM VECTOR_SEARCH(\n",
    "        TABLE `{PROJECT}.{DATASET}.song_line_embeddings`,\n",
    "        'line_vec',\n",
    "        (SELECT theme_vec FROM theme),\n",
    "        top_k => @tk,\n",
    "        distance_type => 'COSINE'\n",
    "      )\n",
    "    ),\n",
    "    best AS (\n",
    "      SELECT song_id, song_title, line_id, line_text, distance,\n",
    "             ROW_NUMBER() OVER (PARTITION BY song_id ORDER BY distance) rn\n",
    "      FROM lines\n",
    "    )\n",
    "    SELECT song_id, song_title, line_id, line_text, distance,\n",
    "           ROW_NUMBER() OVER (ORDER BY distance) AS rank\n",
    "    FROM best\n",
    "    WHERE rn = 1\n",
    "    ORDER BY distance\n",
    "    LIMIT @tk\n",
    "    \"\"\"\n",
    "    job = client.query(sql, job_config=bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\"theme\",\"STRING\",theme),\n",
    "            bigquery.ScalarQueryParameter(\"tk\",\"INT64\",top_k),\n",
    "        ]))\n",
    "    df = job.result().to_dataframe()\n",
    "    df.insert(0,\"theme\",theme)\n",
    "    return df[[\"theme\",\"song_id\",\"song_title\",\"rank\",\"distance\",\"line_id\",\"line_text\"]]\n",
    "\n",
    "themes = [\"God's goodness\",\"Name above all names\", \"Love\"]  # your set\n",
    "res = pd.concat([search_and_rank(t) for t in themes], ignore_index=True)\n",
    "\n",
    "# write results to a reproducible table\n",
    "# client.load_table_from_dataframe(res, f\"{PROJECT}.{DATASET}.eval_results\").result()\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c3505-ebea-48f7-8543-6dd2749f3617",
   "metadata": {},
   "source": [
    "### Define functions to calculate our NDCG and MRR metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8e300780-3f72-404d-ae99-434639f4b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        NDCG@k  MRR@k\n",
      "theme                                \n",
      "God's goodness        0.613147    1.0\n",
      "Love                  1.000000    1.0\n",
      "Name above all names  0.575329    0.5\n",
      "Mean NDCG@k: 0.7294921259892352\n",
      "Mean MRR@k: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "\n",
    "k = 5\n",
    "scored = res.merge(labels, on=[\"theme\",\"song_title\"], how=\"left\").fillna({\"rel\":0})\n",
    "\n",
    "def ndcg_at_k(df, k):\n",
    "    dfk = df.nsmallest(k, \"rank\")\n",
    "    rels = dfk.sort_values(\"rank\")[\"rel\"].tolist()\n",
    "    dcg = sum(((2**r - 1)/log2(i+2) for i,r in enumerate(rels)))\n",
    "    ideal = sorted(df[\"rel\"].tolist(), reverse=True)[:k]\n",
    "    idcg = sum(((2**r - 1)/log2(i+2) for i,r in enumerate(ideal))) or 1.0\n",
    "    return dcg/idcg\n",
    "\n",
    "def mrr_at_k(df, k):\n",
    "    dfk = df.nsmallest(k, \"rank\")\n",
    "    hits = dfk[dfk[\"rel\"]>0].sort_values(\"rank\")[\"rank\"].tolist()\n",
    "    return 1.0/hits[0] if hits else 0.0\n",
    "\n",
    "scores = scored.groupby(\"theme\").apply(lambda g: pd.Series({\n",
    "    \"NDCG@k\": ndcg_at_k(g, k),\n",
    "    \"MRR@k\":  mrr_at_k(g, k)\n",
    "}), include_groups=False)\n",
    "print(scores)\n",
    "print(\"Mean NDCG@k:\", scores[\"NDCG@k\"].mean())\n",
    "print(\"Mean MRR@k:\",  scores[\"MRR@k\"].mean())\n",
    "# scored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc77b93-1a16-4be5-9767-167797183d48",
   "metadata": {},
   "source": [
    "### We calculated 2 metrics:\n",
    "1. **Normalized Discounted Cumulative Gain (NDCG)** - A standard metric for graded relevance\n",
    "2. **Mean Reciprocal Rank (MMR)** - A metric that measures the first relevant hit/result\n",
    "   \n",
    "We use our hand-labeled data (labels) as a standard to validate the results of our vector search.  The closer the values of NDCG and MRR are to 1 (see above), the more reliable our results.  During testing, the results ranged between 0.75 - 0.83 on both metrics, indicating that highly relevant songs rank near the top, and the first relevant hit typically appears within the top 5 (see above k = 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e500ac3-e332-4525-9d83-19e80b442e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
